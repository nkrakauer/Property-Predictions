{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"next\" href=\"/product-lines/silanes/?pl_page=2&amp;perpage=50&amp;product-code-filter=SIA\">&gt;</a>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.gelest.com/product-lines/silanes/?pl_page=1&perpage=50&product-code-filter=SIA'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "products = soup.find(\"div\", {\"class\": re.compile(\"^(first border-box col-xs-24)\")})\n",
    "href = soup.find(\"a\", {\"class\": \"next\"})\n",
    "newPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gelest.com/product-lines/silanes/?pl_page=2&perpage=50&product-code-filter=SIA'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = 'https://www.gelest.com'+newPage['href']\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-13-2647cd01aeb8>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-2647cd01aeb8>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    print(\"-------------------Page\"+str(num)+\"------------------------------------------\")\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#helper methods\n",
    "def getFlashPoint(pdfUrl):\n",
    "    flashp = -1\n",
    "    response = urlopen(pdfUrl)\n",
    "    file = open(\"document.pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()\n",
    "    pdf_file = open('document.pdf', 'rb')\n",
    "        \n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    \n",
    "    #number_of_pages = read_pdf.getNumPages()\n",
    "    for p in range(read_pdf.getNumPages()):\n",
    "        page = read_pdf.getPage(p)\n",
    "        text = page.extractText()\n",
    "        \n",
    "        text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "        fp = re.search('Flash point(.+?)C', text)\n",
    "        #print(fp)\n",
    "        if fp != None:\n",
    "            fp = re.search('Flash point(.+?)C', text).group(0)\n",
    "            flashPoint = re.findall('\\d+', fp)\n",
    "            #print(int(flashPoint[0]))\n",
    "            flashp = int(flashPoint[0])\n",
    "            break\n",
    "    \n",
    "    pdf_file.close()\n",
    "    \n",
    "    print(flashp)    \n",
    "    return flashp\n",
    "\n",
    "def removeJunk(compound):\n",
    "    compound = compound.split(',')\n",
    "    return compound[0]\n",
    "\n",
    "def scrap(url, frame, pageNumber):\n",
    "    num = 1\n",
    "    while num <= pageNumber:\n",
    "    print(\"-------------------Page\"+str(num)+\"------------------------------------------\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    products = soup.find(\"div\", {\"class\": re.compile(\"^(first border-box col-xs-24)\")})\n",
    "    contents = soup.find_all(\"div\", {\"class\": \"wc-product-meta\"})\n",
    "    imgs = soup.find_all(\"img\", {\"class\": \"img-responsive center-block wp-post-image\"})\n",
    "    \n",
    "    for img, data in zip(imgs, contents):\n",
    "        \n",
    "        productCode = data.find(\"span\", {\"class\" : \"code\"}).text\n",
    "        sds = soup.find(\"a\", {\"href\": \"https://s3.amazonaws.com/gelest/sds/\"+productCode+\"_GHS+US_English+US.pdf\"})\n",
    "        casNo = data.find(\"span\", {\"class\" : \"cas-number\"})\n",
    "    \n",
    "        if casNo == None:\n",
    "            casNo = ''\n",
    "        else:\n",
    "            casNo = casNo.text\n",
    "        \n",
    "        compound = data.find(\"p\", {\"class\" : \"title\"}).text.strip('\\n\\t')\n",
    "        compound = removeJunk(compound)\n",
    "        smilesUrl = \"https://opsin.ch.cam.ac.uk/opsin/\"+compound+\".smi\"\n",
    "        print(smilesUrl)\n",
    "        requestSmiles = requests.get(smilesUrl)\n",
    "    \n",
    "        if requestSmiles.status_code == 400 or requestSmiles.status_code == 404:\n",
    "            print(\"no smiles\")\n",
    "        else:\n",
    "            try:\n",
    "                if sds != None: #if sds['href'] != None:\n",
    "                    #print(sds['href'])\n",
    "                    if sds == None:\n",
    "                        flashPoint = -1\n",
    "                    else:\n",
    "                        flashPoint = getFlashPoint(sds['href'])\n",
    "                    frame = frame.append({'productCode' : productCode,\n",
    "                             'casNum' : casNo,\n",
    "                             'compound' : compound,\n",
    "                              'smiles' : requestSmiles.text,\n",
    "                              'flashPoint' : flashPoint,\n",
    "                             'img' : img['src'],\n",
    "                             'sds' : sds['href']}, ignore_index=True)\n",
    "            except:\n",
    "                print('could not scrap pdf')\n",
    "                #print(compound, requestSmiles.text, flashPoint)\n",
    "                #print(sds[\"href\"])\n",
    "\n",
    "    num+= 1\n",
    "    href = soup.find(\"a\", {\"class\": \"next\"})\n",
    "    url = 'https://www.gelest.com'+href['href']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b36f9a62245c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"productCode\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"casNum\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compound\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"smiles\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flashPoint\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"img\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#frame for scraped data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.gelest.com/product-lines/silanes/?pl_page=1&perpage=50&product-code-filter=SIA'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scrap' is not defined"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "frame = pd.DataFrame(columns=(\"productCode\", \"casNum\", \"compound\", \"smiles\", \"flashPoint\", \"img\", \"sds\")) #frame for scraped data\n",
    "url = 'https://www.gelest.com/product-lines/silanes/?pl_page=1&perpage=50&product-code-filter=SIA'\n",
    "scrap(url, frame, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
